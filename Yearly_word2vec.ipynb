{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f2a953f-f3b6-43de-a985-a7482935f920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://midway3-0172.rcc.local:4041\n"
     ]
    }
   ],
   "source": [
    "print(sc.uiWebUrl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80947ba6-1ade-457e-bcbd-3fb8364dd883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n",
      "          41323339   caslake _interac    yjia2  R       6:00      1 midway3-0172\n"
     ]
    }
   ],
   "source": [
    "! squeue -u yjia2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6ac70ca-2344-43a5-bc44-437c621a8461",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "font_path = \"/home/yjia2/fonts/NotoSansCJKsc-Regular.otf\"  \n",
    "fm.fontManager.addfont(font_path)\n",
    "zh_font = fm.FontProperties(fname=font_path)\n",
    "\n",
    "plt.rcParams[\"font.family\"] = zh_font.get_name()\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False\n",
    "\n",
    "from pyspark.sql import functions as F, types as T\n",
    "from pyspark.ml.functions import vector_to_array\n",
    "from pyspark.storagelevel import StorageLevel\n",
    "from pyspark.ml.feature import Word2VecModel\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from pyspark.ml.feature import Word2Vec\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e39c6bf9-69c9-4ec1-990e-27486171912d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 14:=====================================================>(248 + 3) / 251]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+--------+\n",
      "|year|n_docs|n_tokens|\n",
      "+----+------+--------+\n",
      "|1947|10769 |2711874 |\n",
      "+----+------+--------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Pre-processing\n",
    "\n",
    "BASE_PATH = \"cleaned_segmented_parquet\"\n",
    "\n",
    "df_raw = spark.read.parquet(BASE_PATH)\n",
    "\n",
    "df = (\n",
    "    df_raw\n",
    "    .withColumnRenamed(\"文本内容_清洗\", \"content_cleaned\")\n",
    "    .withColumnRenamed(\"年份\", \"year\")\n",
    "    .select(\"content_cleaned\", \"year\")\n",
    ")\n",
    "\n",
    "df = df.withColumn(\"year\", F.col(\"year\").cast(\"int\"))\n",
    "\n",
    "df = (\n",
    "    df\n",
    "    .withColumn(\"content_cleaned\", F.trim(F.col(\"content_cleaned\")))\n",
    "    .filter(\n",
    "        F.col(\"content_cleaned\").isNotNull()\n",
    "        & (F.length(\"content_cleaned\") > 0)\n",
    "    )\n",
    ")\n",
    "\n",
    "df = (\n",
    "    df\n",
    "    .withColumn(\"tokens\", F.split(F.col(\"content_cleaned\"), r\"\\s+\"))\n",
    "    .withColumn(\"tokens\", F.expr(\"filter(tokens, x -> x <> '')\"))\n",
    ")\n",
    "\n",
    "df = (\n",
    "    df\n",
    "    .withColumn(\"len_tokens\", F.size(\"tokens\"))\n",
    "    .filter(F.col(\"len_tokens\") >= 3)\n",
    "    .drop(\"len_tokens\")\n",
    ")\n",
    "\n",
    "year_stats = (\n",
    "    df.groupBy(\"year\")\n",
    "      .agg(\n",
    "          F.count(\"*\").alias(\"n_docs\"),\n",
    "          F.sum(F.size(\"tokens\")).alias(\"n_tokens\")\n",
    "      )\n",
    "      .orderBy(\"year\")\n",
    ")\n",
    "\n",
    "year_stats.show(1, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5b6f9ad-c655-4184-a5a4-0fc5da032a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word2Vec hyper-parameters \n",
    "W2V_PARAMS = dict(\n",
    "    vectorSize=150,\n",
    "    windowSize=6,\n",
    "    minCount=30,\n",
    "    maxIter=3,          # epochs\n",
    "    stepSize=0.025,     # learning rate\n",
    "    numPartitions=100,\n",
    "    maxSentenceLength=600,\n",
    "    seed=42,\n",
    "    inputCol=\"tokens\",\n",
    "    outputCol=\"w2v_features\"\n",
    ")\n",
    "\n",
    "BASE_MODEL_DIR = \"w2v_models/pd_w2v_vs150_mc30_ep3_ws6_by_year\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83db74f2-5881-4472-aca3-02a0df2de08d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 24:>                                                         (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Years to train: [1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956] ... total = 78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "years = (\n",
    "    df.select(\"year\")\n",
    "      .distinct()\n",
    "      .orderBy(\"year\")\n",
    "      .rdd.map(lambda r: r[\"year\"])\n",
    "      .collect()\n",
    ")\n",
    "\n",
    "print(\"Years to train:\", years[:10], \"... total =\", len(years))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3c8f7e6-89f1-4ea1-af9f-89cb2a007d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Training year 1947 =====\n",
      "Docs in 1947 = 10769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1947: cached training corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1947: model trained\n",
      "1947: saving model to w2v_models/pd_w2v_vs150_mc30_ep3_ws6_by_year/year=1947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1947: vocab_size = 10630\n",
      "\n",
      "===== Training year 1948 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs in 1948 = 8246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1948: cached training corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1948: model trained\n",
      "1948: saving model to w2v_models/pd_w2v_vs150_mc30_ep3_ws6_by_year/year=1948\n",
      "1948: vocab_size = 9372\n",
      "\n",
      "===== Training year 1949 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs in 1949 = 18956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1949: cached training corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1949: model trained\n",
      "1949: saving model to w2v_models/pd_w2v_vs150_mc30_ep3_ws6_by_year/year=1949\n",
      "1949: vocab_size = 17189\n",
      "\n",
      "===== Training year 1950 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs in 1950 = 19990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1950: cached training corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1950: model trained\n",
      "1950: saving model to w2v_models/pd_w2v_vs150_mc30_ep3_ws6_by_year/year=1950\n",
      "1950: vocab_size = 18651\n",
      "\n",
      "===== Training year 1951 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs in 1951 = 13756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1951: cached training corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1951: model trained\n",
      "1951: saving model to w2v_models/pd_w2v_vs150_mc30_ep3_ws6_by_year/year=1951\n",
      "1951: vocab_size = 15638\n",
      "\n",
      "===== Training year 1952 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs in 1952 = 13381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1952: cached training corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1952: model trained\n",
      "1952: saving model to w2v_models/pd_w2v_vs150_mc30_ep3_ws6_by_year/year=1952\n",
      "1952: vocab_size = 15649\n",
      "\n",
      "===== Training year 1953 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs in 1953 = 12790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1953: cached training corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1953: model trained\n",
      "1953: saving model to w2v_models/pd_w2v_vs150_mc30_ep3_ws6_by_year/year=1953\n",
      "1953: vocab_size = 15426\n",
      "\n",
      "===== Training year 1954 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs in 1954 = 13968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1954: cached training corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1954: model trained\n",
      "1954: saving model to w2v_models/pd_w2v_vs150_mc30_ep3_ws6_by_year/year=1954\n",
      "1954: vocab_size = 14829\n",
      "\n",
      "===== Training year 1955 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs in 1955 = 15612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1955: cached training corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1955: model trained\n",
      "1955: saving model to w2v_models/pd_w2v_vs150_mc30_ep3_ws6_by_year/year=1955\n",
      "1955: vocab_size = 15561\n",
      "\n",
      "===== Training year 1956 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs in 1956 = 23691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1956: cached training corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1956: model trained\n",
      "1956: saving model to w2v_models/pd_w2v_vs150_mc30_ep3_ws6_by_year/year=1956\n",
      "1956: vocab_size = 18127\n",
      "\n",
      "===== Training year 1957 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs in 1957 = 25363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1957: cached training corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1957: model trained\n",
      "1957: saving model to w2v_models/pd_w2v_vs150_mc30_ep3_ws6_by_year/year=1957\n",
      "1957: vocab_size = 21444\n",
      "\n",
      "===== Training year 1958 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs in 1958 = 28012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1958: cached training corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1958: model trained\n",
      "1958: saving model to w2v_models/pd_w2v_vs150_mc30_ep3_ws6_by_year/year=1958\n",
      "1958: vocab_size = 21781\n",
      "\n",
      "===== Training year 1959 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs in 1959 = 22785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1959: cached training corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1959: model trained\n",
      "1959: saving model to w2v_models/pd_w2v_vs150_mc30_ep3_ws6_by_year/year=1959\n",
      "1959: vocab_size = 22565\n",
      "\n",
      "===== Training year 1960 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs in 1960 = 23386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1960: cached training corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1960: model trained\n",
      "1960: saving model to w2v_models/pd_w2v_vs150_mc30_ep3_ws6_by_year/year=1960\n",
      "1960: vocab_size = 21979\n",
      "\n",
      "===== Training year 1961 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs in 1961 = 21957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1961: cached training corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1961: model trained\n",
      "1961: saving model to w2v_models/pd_w2v_vs150_mc30_ep3_ws6_by_year/year=1961\n",
      "1961: vocab_size = 19853\n",
      "\n",
      "===== Training year 1962 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs in 1962 = 17310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1962: cached training corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1962: model trained\n",
      "1962: saving model to w2v_models/pd_w2v_vs150_mc30_ep3_ws6_by_year/year=1962\n",
      "1962: vocab_size = 16279\n",
      "\n",
      "===== Training year 1963 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs in 1963 = 15189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1963: cached training corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1963: model trained\n",
      "1963: saving model to w2v_models/pd_w2v_vs150_mc30_ep3_ws6_by_year/year=1963\n",
      "1963: vocab_size = 15311\n",
      "\n",
      "===== Training year 1964 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs in 1964 = 16606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1964: cached training corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1964: model trained\n",
      "1964: saving model to w2v_models/pd_w2v_vs150_mc30_ep3_ws6_by_year/year=1964\n",
      "1964: vocab_size = 16595\n",
      "\n",
      "===== Training year 1965 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs in 1965 = 16221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1965: cached training corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1965: model trained\n",
      "1965: saving model to w2v_models/pd_w2v_vs150_mc30_ep3_ws6_by_year/year=1965\n",
      "1965: vocab_size = 15970\n",
      "\n",
      "===== Training year 1966 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs in 1966 = 12171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1966: cached training corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1966: model trained\n",
      "1966: saving model to w2v_models/pd_w2v_vs150_mc30_ep3_ws6_by_year/year=1966\n",
      "1966: vocab_size = 13148\n",
      "\n",
      "===== Training year 1967 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs in 1967 = 9274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1967: cached training corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1967: model trained\n",
      "1967: saving model to w2v_models/pd_w2v_vs150_mc30_ep3_ws6_by_year/year=1967\n",
      "1967: vocab_size = 9744\n",
      "\n",
      "===== Training year 1968 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs in 1968 = 9216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1968: cached training corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1968: model trained\n",
      "1968: saving model to w2v_models/pd_w2v_vs150_mc30_ep3_ws6_by_year/year=1968\n",
      "1968: vocab_size = 10021\n",
      "\n",
      "===== Training year 1969 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs in 1969 = 10124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1969: cached training corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1969: model trained\n",
      "1969: saving model to w2v_models/pd_w2v_vs150_mc30_ep3_ws6_by_year/year=1969\n",
      "1969: vocab_size = 10851\n",
      "\n",
      "===== Training year 1970 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs in 1970 = 10570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1970: cached training corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1970: model trained\n",
      "1970: saving model to w2v_models/pd_w2v_vs150_mc30_ep3_ws6_by_year/year=1970\n",
      "1970: vocab_size = 11448\n",
      "\n",
      "===== Training year 1971 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs in 1971 = 10421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1971: cached training corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1971: model trained\n",
      "1971: saving model to w2v_models/pd_w2v_vs150_mc30_ep3_ws6_by_year/year=1971\n",
      "1971: vocab_size = 10916\n",
      "\n",
      "===== Training year 1972 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs in 1972 = 14333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1972: cached training corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1972: model trained\n",
      "1972: saving model to w2v_models/pd_w2v_vs150_mc30_ep3_ws6_by_year/year=1972\n",
      "1972: vocab_size = 12454\n",
      "\n",
      "===== Training year 1973 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs in 1973 = 14845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1973: cached training corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1973: model trained\n",
      "1973: saving model to w2v_models/pd_w2v_vs150_mc30_ep3_ws6_by_year/year=1973\n",
      "1973: vocab_size = 13151\n",
      "\n",
      "===== Training year 1974 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs in 1974 = 12837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1974: cached training corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1974: model trained\n",
      "1974: saving model to w2v_models/pd_w2v_vs150_mc30_ep3_ws6_by_year/year=1974\n",
      "1974: vocab_size = 12942\n",
      "\n",
      "===== Training year 1975 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs in 1975 = 13362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1975: cached training corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1975: model trained\n",
      "1975: saving model to w2v_models/pd_w2v_vs150_mc30_ep3_ws6_by_year/year=1975\n",
      "1975: vocab_size = 12445\n",
      "\n",
      "===== Training year 1976 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs in 1976 = 12262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1976: cached training corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1976: model trained\n",
      "1976: saving model to w2v_models/pd_w2v_vs150_mc30_ep3_ws6_by_year/year=1976\n",
      "1976: vocab_size = 11610\n",
      "\n",
      "===== Training year 1977 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs in 1977 = 12715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1977: cached training corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1977: model trained\n",
      "1977: saving model to w2v_models/pd_w2v_vs150_mc30_ep3_ws6_by_year/year=1977\n",
      "1977: vocab_size = 12849\n",
      "\n",
      "===== Training year 1978 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs in 1978 = 13431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1978: cached training corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1978: model trained\n",
      "1978: saving model to w2v_models/pd_w2v_vs150_mc30_ep3_ws6_by_year/year=1978\n",
      "1978: vocab_size = 14525\n",
      "\n",
      "===== Training year 1979 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs in 1979 = 17537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1979: cached training corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1979: model trained\n",
      "1979: saving model to w2v_models/pd_w2v_vs150_mc30_ep3_ws6_by_year/year=1979\n",
      "1979: vocab_size = 17176\n",
      "\n",
      "===== Training year 1980 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs in 1980 = 27226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1980: cached training corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1980: model trained\n",
      "1980: saving model to w2v_models/pd_w2v_vs150_mc30_ep3_ws6_by_year/year=1980\n",
      "1980: vocab_size = 20371\n",
      "\n",
      "===== Training year 1981 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs in 1981 = 28360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1981: cached training corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1981: model trained\n",
      "1981: saving model to w2v_models/pd_w2v_vs150_mc30_ep3_ws6_by_year/year=1981\n",
      "1981: vocab_size = 20841\n",
      "\n",
      "===== Training year 1982 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs in 1982 = 28324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1982: cached training corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1982: model trained\n",
      "1982: saving model to w2v_models/pd_w2v_vs150_mc30_ep3_ws6_by_year/year=1982\n",
      "1982: vocab_size = 20705\n",
      "\n",
      "===== Training year 1983 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs in 1983 = 31138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1983: cached training corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1983: model trained\n",
      "1983: saving model to w2v_models/pd_w2v_vs150_mc30_ep3_ws6_by_year/year=1983\n",
      "1983: vocab_size = 20278\n",
      "\n",
      "===== Training year 1984 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs in 1984 = 31964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1984: cached training corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1984: model trained\n",
      "1984: saving model to w2v_models/pd_w2v_vs150_mc30_ep3_ws6_by_year/year=1984\n",
      "1984: vocab_size = 21164\n",
      "\n",
      "===== Training year 1985 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs in 1985 = 34299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1985: cached training corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1985: model trained\n",
      "1985: saving model to w2v_models/pd_w2v_vs150_mc30_ep3_ws6_by_year/year=1985\n",
      "1985: vocab_size = 22854\n",
      "\n",
      "===== Training year 1986 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs in 1986 = 33502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1986: cached training corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1986: model trained\n",
      "1986: saving model to w2v_models/pd_w2v_vs150_mc30_ep3_ws6_by_year/year=1986\n",
      "1986: vocab_size = 23095\n",
      "\n",
      "===== Training year 1987 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs in 1987 = 32663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1987: cached training corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1987: model trained\n",
      "1987: saving model to w2v_models/pd_w2v_vs150_mc30_ep3_ws6_by_year/year=1987\n",
      "1987: vocab_size = 22589\n",
      "\n",
      "===== Training year 1988 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs in 1988 = 33530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1988: cached training corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1988: model trained\n",
      "1988: saving model to w2v_models/pd_w2v_vs150_mc30_ep3_ws6_by_year/year=1988\n",
      "1988: vocab_size = 22579\n",
      "\n",
      "===== Training year 1989 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs in 1989 = 30017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1989: cached training corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1989: model trained\n",
      "1989: saving model to w2v_models/pd_w2v_vs150_mc30_ep3_ws6_by_year/year=1989\n",
      "1989: vocab_size = 21810\n",
      "\n",
      "===== Training year 1990 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs in 1990 = 31702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1990: cached training corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1990: model trained\n",
      "1990: saving model to w2v_models/pd_w2v_vs150_mc30_ep3_ws6_by_year/year=1990\n",
      "1990: vocab_size = 21883\n",
      "\n",
      "===== Training year 1991 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs in 1991 = 33818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1991: cached training corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1991: model trained\n",
      "1991: saving model to w2v_models/pd_w2v_vs150_mc30_ep3_ws6_by_year/year=1991\n",
      "1991: vocab_size = 21012\n",
      "\n",
      "===== Training year 1992 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs in 1992 = 37363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1992: cached training corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1992: model trained\n",
      "1992: saving model to w2v_models/pd_w2v_vs150_mc30_ep3_ws6_by_year/year=1992\n",
      "1992: vocab_size = 21540\n",
      "\n",
      "===== Training year 1993 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs in 1993 = 36495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1993: cached training corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1993: model trained\n",
      "1993: saving model to w2v_models/pd_w2v_vs150_mc30_ep3_ws6_by_year/year=1993\n",
      "1993: vocab_size = 21416\n",
      "\n",
      "===== Training year 1994 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs in 1994 = 33985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1994: cached training corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1994: model trained\n",
      "1994: saving model to w2v_models/pd_w2v_vs150_mc30_ep3_ws6_by_year/year=1994\n",
      "1994: vocab_size = 22984\n",
      "\n",
      "===== Training year 1995 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs in 1995 = 37602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1995: cached training corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1995: model trained\n",
      "1995: saving model to w2v_models/pd_w2v_vs150_mc30_ep3_ws6_by_year/year=1995\n",
      "25/11/13 16:05:00 WARN TaskSetManager: Stage 1540 contains a task of very large size (1060 KiB). The maximum recommended task size is 1000 KiB.\n",
      "1995: vocab_size = 25984\n",
      "\n",
      "===== Training year 1996 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs in 1996 = 37116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1996: cached training corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1996: model trained\n",
      "1996: saving model to w2v_models/pd_w2v_vs150_mc30_ep3_ws6_by_year/year=1996\n",
      "25/11/13 16:07:44 WARN TaskSetManager: Stage 1571 contains a task of very large size (1047 KiB). The maximum recommended task size is 1000 KiB.\n",
      "1996: vocab_size = 25683\n",
      "\n",
      "===== Training year 1997 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs in 1997 = 34310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1997: cached training corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1997: model trained\n",
      "1997: saving model to w2v_models/pd_w2v_vs150_mc30_ep3_ws6_by_year/year=1997\n",
      "25/11/13 16:10:15 WARN TaskSetManager: Stage 1602 contains a task of very large size (1052 KiB). The maximum recommended task size is 1000 KiB.\n",
      "1997: vocab_size = 25806\n",
      "\n",
      "===== Training year 1998 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs in 1998 = 33701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1998: cached training corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1998: model trained\n",
      "1998: saving model to w2v_models/pd_w2v_vs150_mc30_ep3_ws6_by_year/year=1998\n",
      "25/11/13 16:12:48 WARN TaskSetManager: Stage 1633 contains a task of very large size (1060 KiB). The maximum recommended task size is 1000 KiB.\n",
      "1998: vocab_size = 25987\n",
      "\n",
      "===== Training year 1999 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs in 1999 = 34816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1999: cached training corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1999: model trained\n",
      "1999: saving model to w2v_models/pd_w2v_vs150_mc30_ep3_ws6_by_year/year=1999\n",
      "25/11/13 16:15:33 WARN TaskSetManager: Stage 1664 contains a task of very large size (1037 KiB). The maximum recommended task size is 1000 KiB.\n",
      "1999: vocab_size = 25434\n",
      "\n",
      "===== Training year 2000 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs in 2000 = 34707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000: cached training corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000: model trained\n",
      "2000: saving model to w2v_models/pd_w2v_vs150_mc30_ep3_ws6_by_year/year=2000\n",
      "25/11/13 16:18:19 WARN TaskSetManager: Stage 1695 contains a task of very large size (1033 KiB). The maximum recommended task size is 1000 KiB.\n",
      "2000: vocab_size = 25338\n",
      "\n",
      "===== Training year 2001 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs in 2001 = 35614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2001: cached training corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2001: model trained\n",
      "2001: saving model to w2v_models/pd_w2v_vs150_mc30_ep3_ws6_by_year/year=2001\n",
      "25/11/13 16:20:55 WARN TaskSetManager: Stage 1726 contains a task of very large size (1018 KiB). The maximum recommended task size is 1000 KiB.\n",
      "2001: vocab_size = 24989\n",
      "\n",
      "===== Training year 2002 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs in 2002 = 34787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2002: cached training corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2002: model trained\n",
      "2002: saving model to w2v_models/pd_w2v_vs150_mc30_ep3_ws6_by_year/year=2002\n",
      "25/11/13 16:23:38 WARN TaskSetManager: Stage 1757 contains a task of very large size (1007 KiB). The maximum recommended task size is 1000 KiB.\n",
      "2002: vocab_size = 24692\n",
      "\n",
      "===== Training year 2003 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs in 2003 = 39173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2003: cached training corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2003: model trained\n",
      "2003: saving model to w2v_models/pd_w2v_vs150_mc30_ep3_ws6_by_year/year=2003\n",
      "25/11/13 16:27:03 WARN TaskSetManager: Stage 1788 contains a task of very large size (1198 KiB). The maximum recommended task size is 1000 KiB.\n",
      "2003: vocab_size = 29406\n",
      "\n",
      "===== Training year 2004 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs in 2004 = 38535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2004: cached training corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2004: model trained\n",
      "2004: saving model to w2v_models/pd_w2v_vs150_mc30_ep3_ws6_by_year/year=2004\n",
      "25/11/13 16:30:16 WARN TaskSetManager: Stage 1819 contains a task of very large size (1184 KiB). The maximum recommended task size is 1000 KiB.\n",
      "2004: vocab_size = 29050\n",
      "\n",
      "===== Training year 2005 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs in 2005 = 36653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2005: cached training corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2005: model trained\n",
      "2005: saving model to w2v_models/pd_w2v_vs150_mc30_ep3_ws6_by_year/year=2005\n",
      "25/11/13 16:33:49 WARN TaskSetManager: Stage 1850 contains a task of very large size (1168 KiB). The maximum recommended task size is 1000 KiB.\n",
      "2005: vocab_size = 28664\n",
      "\n",
      "===== Training year 2006 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs in 2006 = 36454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2006: cached training corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2006: model trained\n",
      "2006: saving model to w2v_models/pd_w2v_vs150_mc30_ep3_ws6_by_year/year=2006\n",
      "25/11/13 16:37:32 WARN TaskSetManager: Stage 1881 contains a task of very large size (1168 KiB). The maximum recommended task size is 1000 KiB.\n",
      "2006: vocab_size = 28658\n",
      "\n",
      "===== Training year 2007 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs in 2007 = 35574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2007: cached training corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2007: model trained\n",
      "2007: saving model to w2v_models/pd_w2v_vs150_mc30_ep3_ws6_by_year/year=2007\n",
      "25/11/13 16:40:36 WARN TaskSetManager: Stage 1912 contains a task of very large size (1152 KiB). The maximum recommended task size is 1000 KiB.\n",
      "2007: vocab_size = 28285\n",
      "\n",
      "===== Training year 2008 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs in 2008 = 32226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2008: cached training corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2008: model trained\n",
      "2008: saving model to w2v_models/pd_w2v_vs150_mc30_ep3_ws6_by_year/year=2008\n",
      "25/11/13 16:43:47 WARN TaskSetManager: Stage 1943 contains a task of very large size (1098 KiB). The maximum recommended task size is 1000 KiB.\n",
      "2008: vocab_size = 26939\n",
      "\n",
      "===== Training year 2009 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs in 2009 = 33795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2009: cached training corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2009: model trained\n",
      "2009: saving model to w2v_models/pd_w2v_vs150_mc30_ep3_ws6_by_year/year=2009\n",
      "25/11/13 16:47:57 WARN TaskSetManager: Stage 1974 contains a task of very large size (1175 KiB). The maximum recommended task size is 1000 KiB.\n",
      "2009: vocab_size = 28802\n",
      "\n",
      "===== Training year 2010 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs in 2010 = 42658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010: cached training corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010: model trained\n",
      "2010: saving model to w2v_models/pd_w2v_vs150_mc30_ep3_ws6_by_year/year=2010\n",
      "25/11/13 16:52:28 WARN TaskSetManager: Stage 2005 contains a task of very large size (1364 KiB). The maximum recommended task size is 1000 KiB.\n",
      "2010: vocab_size = 33482\n",
      "\n",
      "===== Training year 2011 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs in 2011 = 39661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011: cached training corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011: model trained\n",
      "2011: saving model to w2v_models/pd_w2v_vs150_mc30_ep3_ws6_by_year/year=2011\n",
      "25/11/13 16:57:40 WARN TaskSetManager: Stage 2036 contains a task of very large size (1402 KiB). The maximum recommended task size is 1000 KiB.\n",
      "2011: vocab_size = 34427\n",
      "\n",
      "===== Training year 2012 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs in 2012 = 37041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2012: cached training corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2012: model trained\n",
      "2012: saving model to w2v_models/pd_w2v_vs150_mc30_ep3_ws6_by_year/year=2012\n",
      "25/11/13 17:02:05 WARN TaskSetManager: Stage 2067 contains a task of very large size (1344 KiB). The maximum recommended task size is 1000 KiB.\n",
      "2012: vocab_size = 32990\n",
      "\n",
      "===== Training year 2013 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs in 2013 = 40442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2013: cached training corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2013: model trained\n",
      "2013: saving model to w2v_models/pd_w2v_vs150_mc30_ep3_ws6_by_year/year=2013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/11/13 17:07:12 WARN TaskSetManager: Stage 2098 contains a task of very large size (1440 KiB). The maximum recommended task size is 1000 KiB.\n",
      "2013: vocab_size = 35342\n",
      "\n",
      "===== Training year 2014 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs in 2014 = 40244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014: cached training corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014: model trained\n",
      "2014: saving model to w2v_models/pd_w2v_vs150_mc30_ep3_ws6_by_year/year=2014\n",
      "25/11/13 17:11:32 WARN TaskSetManager: Stage 2129 contains a task of very large size (1446 KiB). The maximum recommended task size is 1000 KiB.\n",
      "2014: vocab_size = 35515\n",
      "\n",
      "===== Training year 2015 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs in 2015 = 38856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015: cached training corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015: model trained\n",
      "2015: saving model to w2v_models/pd_w2v_vs150_mc30_ep3_ws6_by_year/year=2015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/11/13 17:16:11 WARN TaskSetManager: Stage 2160 contains a task of very large size (1439 KiB). The maximum recommended task size is 1000 KiB.\n",
      "2015: vocab_size = 35304\n",
      "\n",
      "===== Training year 2016 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs in 2016 = 37060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016: cached training corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016: model trained\n",
      "2016: saving model to w2v_models/pd_w2v_vs150_mc30_ep3_ws6_by_year/year=2016\n",
      "25/11/13 17:21:11 WARN TaskSetManager: Stage 2191 contains a task of very large size (1409 KiB). The maximum recommended task size is 1000 KiB.\n",
      "2016: vocab_size = 34561\n",
      "\n",
      "===== Training year 2017 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs in 2017 = 35296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017: cached training corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017: model trained\n",
      "2017: saving model to w2v_models/pd_w2v_vs150_mc30_ep3_ws6_by_year/year=2017\n",
      "25/11/13 17:25:46 WARN TaskSetManager: Stage 2222 contains a task of very large size (1347 KiB). The maximum recommended task size is 1000 KiB.\n",
      "2017: vocab_size = 33087\n",
      "\n",
      "===== Training year 2018 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs in 2018 = 33780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018: cached training corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018: model trained\n",
      "2018: saving model to w2v_models/pd_w2v_vs150_mc30_ep3_ws6_by_year/year=2018\n",
      "25/11/13 17:30:34 WARN TaskSetManager: Stage 2253 contains a task of very large size (1341 KiB). The maximum recommended task size is 1000 KiB.\n",
      "2018: vocab_size = 32903\n",
      "\n",
      "===== Training year 2019 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs in 2019 = 24557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019: cached training corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019: model trained\n",
      "2019: saving model to w2v_models/pd_w2v_vs150_mc30_ep3_ws6_by_year/year=2019\n",
      "25/11/13 17:33:53 WARN TaskSetManager: Stage 2284 contains a task of very large size (1124 KiB). The maximum recommended task size is 1000 KiB.\n",
      "2019: vocab_size = 27564\n",
      "\n",
      "===== Training year 2020 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs in 2020 = 25675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020: cached training corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020: model trained\n",
      "2020: saving model to w2v_models/pd_w2v_vs150_mc30_ep3_ws6_by_year/year=2020\n",
      "25/11/13 17:37:18 WARN TaskSetManager: Stage 2315 contains a task of very large size (1104 KiB). The maximum recommended task size is 1000 KiB.\n",
      "2020: vocab_size = 27086\n",
      "\n",
      "===== Training year 2021 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs in 2021 = 23474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021: cached training corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021: model trained\n",
      "2021: saving model to w2v_models/pd_w2v_vs150_mc30_ep3_ws6_by_year/year=2021\n",
      "25/11/13 17:40:51 WARN TaskSetManager: Stage 2346 contains a task of very large size (1069 KiB). The maximum recommended task size is 1000 KiB.\n",
      "2021: vocab_size = 26239\n",
      "\n",
      "===== Training year 2022 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs in 2022 = 22248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022: cached training corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022: model trained\n",
      "2022: saving model to w2v_models/pd_w2v_vs150_mc30_ep3_ws6_by_year/year=2022\n",
      "2022: vocab_size = 24397\n",
      "\n",
      "===== Training year 2023 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs in 2023 = 24397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023: cached training corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023: model trained\n",
      "2023: saving model to w2v_models/pd_w2v_vs150_mc30_ep3_ws6_by_year/year=2023\n",
      "25/11/13 17:47:42 WARN TaskSetManager: Stage 2408 contains a task of very large size (1061 KiB). The maximum recommended task size is 1000 KiB.\n",
      "2023: vocab_size = 26018\n",
      "\n",
      "===== Training year 2024 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs in 2024 = 17096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024: cached training corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024: model trained\n",
      "2024: saving model to w2v_models/pd_w2v_vs150_mc30_ep3_ws6_by_year/year=2024\n",
      "2024: vocab_size = 19852\n",
      "\n",
      "All yearly trainings done.\n"
     ]
    }
   ],
   "source": [
    "MIN_DOCS = 500\n",
    "\n",
    "for y in years:\n",
    "    print(f\"\\n===== Training year {y} =====\")\n",
    "\n",
    "    df_y = (\n",
    "        df.filter(F.col(\"year\") == y)\n",
    "          .select(\"tokens\")\n",
    "    )\n",
    "\n",
    "    n_docs = df_y.count()\n",
    "    print(f\"Docs in {y} = {n_docs}\")\n",
    "\n",
    "    if n_docs < MIN_DOCS:\n",
    "        print(f\"Skip {y} (n_docs < MIN_DOCS={MIN_DOCS})\")\n",
    "        continue\n",
    "\n",
    "    df_y_train = df_y.repartition(100).persist(StorageLevel.MEMORY_AND_DISK)\n",
    "    _ = df_y_train.count()   \n",
    "    print(f\"{y}: cached training corpus\")\n",
    "\n",
    "    w2v = Word2Vec(**W2V_PARAMS)\n",
    "    w2v_model = w2v.fit(df_y_train)\n",
    "    print(f\"{y}: model trained\")\n",
    "\n",
    "    df_y_train.unpersist()\n",
    "\n",
    "    model_dir = f\"{BASE_MODEL_DIR}/year={y}\"\n",
    "    print(f\"{y}: saving model to {model_dir}\")\n",
    "    w2v_model.write().overwrite().save(model_dir)\n",
    "\n",
    "    vecs = w2v_model.getVectors()   # DataFrame[word: string, vector: vector]\n",
    "    vecs.write.mode(\"overwrite\").parquet(f\"{model_dir}/vectors_parquet\")\n",
    "\n",
    "    vocab_size = vecs.count()\n",
    "    print(f\"{y}: vocab_size = {vocab_size}\")\n",
    "\n",
    "print(\"\\nAll yearly trainings done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1007597d-3173-4c70-873d-4be4310c514d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Year 1950 | word = 人民 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+\n",
      "|word    |similarity         |\n",
      "+--------+-------------------+\n",
      "|万众一心|0.5745235085487366 |\n",
      "|正义事业|0.5567136406898499 |\n",
      "|自由民主|0.5509663820266724 |\n",
      "|死敌    |0.5310417413711548 |\n",
      "|人民意志|0.5274190306663513 |\n",
      "|正义    |0.5226737260818481 |\n",
      "|各族人民|0.5216115117073059 |\n",
      "|英勇斗争|0.5147422552108765 |\n",
      "|不可动摇|0.5076724290847778 |\n",
      "|爱好和平|0.5045686960220337 |\n",
      "|正义战争|0.5042296051979065 |\n",
      "|解放事业|0.5029891133308411 |\n",
      "|深信    |0.5010573863983154 |\n",
      "|坚信    |0.49985629320144653|\n",
      "|亿万人民|0.49916237592697144|\n",
      "+--------+-------------------+\n",
      "\n",
      "\n",
      "=== Year 1978 | word = 人民 ===\n",
      "+--------+------------------+\n",
      "|word    |similarity        |\n",
      "+--------+------------------+\n",
      "|正义事业|0.6518587470054626|\n",
      "|同情    |0.5929450988769531|\n",
      "|始终不渝|0.5833016633987427|\n",
      "|解放事业|0.5722860097885132|\n",
      "|珍视    |0.5614731907844543|\n",
      "|声援    |0.5534377098083496|\n",
      "|愿望    |0.5524501800537109|\n",
      "|正义    |0.5487756133079529|\n",
      "|正义斗争|0.5425110459327698|\n",
      "|衷心祝愿|0.5412216186523438|\n",
      "|昌盛    |0.5387455224990845|\n",
      "|民族解放|0.5379835963249207|\n",
      "|坚信    |0.5296506285667419|\n",
      "|一如既往|0.5283305048942566|\n",
      "|深情厚谊|0.5277685523033142|\n",
      "+--------+------------------+\n",
      "\n",
      "\n",
      "=== Year 1992 | word = 人民 ===\n",
      "+--------+------------------+\n",
      "|word    |similarity        |\n",
      "+--------+------------------+\n",
      "|正义斗争|0.6360828280448914|\n",
      "|血肉    |0.6094914078712463|\n",
      "|解放事业|0.607833743095398 |\n",
      "|各族人民|0.6012633442878723|\n",
      "|亿万人民|0.5929314494132996|\n",
      "|拥护    |0.5794944763183594|\n",
      "|爱戴    |0.5734764337539673|\n",
      "|怀有    |0.572848379611969 |\n",
      "|重托    |0.5696764588356018|\n",
      "|一如既往|0.5668771266937256|\n",
      "|群众    |0.5651937127113342|\n",
      "|民主专政|0.564003586769104 |\n",
      "|正义事业|0.5605691075325012|\n",
      "|忠于党  |0.5602913498878479|\n",
      "|日益增长|0.5526520013809204|\n",
      "+--------+------------------+\n",
      "\n",
      "\n",
      "=== Year 2008 | word = 人民 ===\n",
      "+--------+------------------+\n",
      "|word    |similarity        |\n",
      "+--------+------------------+\n",
      "|深情厚谊|0.661870002746582 |\n",
      "|深厚感情|0.6594746112823486|\n",
      "|依靠人民|0.6355849504470825|\n",
      "|谋利益  |0.6349109411239624|\n",
      "|血肉    |0.5941720008850098|\n",
      "|安危冷暖|0.5674880146980286|\n",
      "|党和政府|0.5610480904579163|\n",
      "|心连心  |0.5543259978294373|\n",
      "|生命财产|0.5486334562301636|\n",
      "|解放事业|0.5460156202316284|\n",
      "|子弟兵  |0.5452693700790405|\n",
      "|愿望    |0.541027843952179 |\n",
      "|共命运  |0.5399457216262817|\n",
      "|不愧为  |0.5339785218238831|\n",
      "|坚信    |0.524111270904541 |\n",
      "+--------+------------------+\n",
      "\n",
      "\n",
      "=== Year 2018 | word = 人民 ===\n",
      "+--------+------------------+\n",
      "|word    |similarity        |\n",
      "+--------+------------------+\n",
      "|依靠人民|0.7667733430862427|\n",
      "|美好生活|0.6886431574821472|\n",
      "|根本利益|0.6425672173500061|\n",
      "|向往    |0.6356478333473206|\n",
      "|血肉    |0.6094900965690613|\n",
      "|根本宗旨|0.6044207215309143|\n",
      "|当家作主|0.593650758266449 |\n",
      "|群众    |0.5783027410507202|\n",
      "|创造者  |0.5744069814682007|\n",
      "|党同    |0.5728572607040405|\n",
      "|心心相印|0.5625379085540771|\n",
      "|日益增长|0.5611090064048767|\n",
      "|共同愿望|0.55941241979599  |\n",
      "|全心全意|0.5584224462509155|\n",
      "|领路人  |0.5555434226989746|\n",
      "+--------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import Word2VecModel\n",
    "\n",
    "BASE_MODEL_DIR = \"w2v_models/pd_w2v_vs150_mc30_ep3_ws6_by_year\"\n",
    "\n",
    "def show_neighbors_for_year(year: int, word: str, topn: int = 20):\n",
    "    \"\"\"\n",
    "    Load the yearly Word2Vec model and show nearest neighbors for a given word.\n",
    "    \"\"\"\n",
    "    model_path = f\"{BASE_MODEL_DIR}/year={year}\"\n",
    "    print(f\"\\n=== Year {year} | word = {word} ===\")\n",
    "\n",
    "    # Load model\n",
    "    w2v_model = Word2VecModel.load(model_path)\n",
    "\n",
    "    # Check if the word exists first (avoid errors)\n",
    "    vecs = w2v_model.getVectors()\n",
    "    if vecs.filter(F.col(\"word\") == word).limit(1).count() == 0:\n",
    "        print(f\"'{word}' not in vocabulary for year {year}.\")\n",
    "        return\n",
    "\n",
    "    # Show nearest neighbors\n",
    "    syn = w2v_model.findSynonyms(word, topn)\n",
    "    syn.show(truncate=False)\n",
    "\n",
    "# Example: check a few years\n",
    "for y in [1950, 1978, 1992, 2008, 2018]:\n",
    "    show_neighbors_for_year(y, \"人民\", topn=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e397c7-53ec-4ec9-ab39-abd993678876",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
